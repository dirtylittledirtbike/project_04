{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime \n",
    "import re\n",
    "from urlextract import URLExtract\n",
    "import spacy\n",
    "import time\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer \n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.decomposition import NMF\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "extractor = URLExtract()\n",
    "# remove all urls from posts\n",
    "def replace_urls(x):\n",
    "    urls = extractor.find_urls(x)\n",
    "    if urls:\n",
    "        x_new = replace_urls(x.replace(urls[0],''))\n",
    "        return x_new\n",
    "    else:\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# little confusing since i went back and grabbed more data from each subreddit. \n",
    "\n",
    "mh_df2 = pd.read_csv('/Users/collinswestnedge/programming/Metis_Online/project_04/data/mentalhealth_rand_large2019.csv', low_memory=False)\n",
    "mh_df =  pd.read_csv('/Users/collinswestnedge/programming/Metis_Online/project_04/data/mh_rand_large.csv', low_memory=False)\n",
    "\n",
    "depression3 = pd.read_csv('/Users/collinswestnedge/programming/Metis_Online/project_04/data/depression_rand_large2019.csv', low_memory=False)\n",
    "depression = pd.read_csv('/Users/collinswestnedge/programming/Metis_Online/project_04/data/depression_rand_large.csv', low_memory=False)\n",
    "\n",
    "mh_df2.drop(columns=['Unnamed: 0'], inplace=True)\n",
    "mh_df.drop(columns=['Unnamed: 0'], inplace=True)\n",
    "\n",
    "depression3.drop(columns=['Unnamed: 0'], inplace=True)\n",
    "depression.drop(columns=['Unnamed: 0'], inplace=True)\n",
    "\n",
    "mh_df2['date'] = mh_df2.created_utc.apply(lambda x: pd.to_datetime(time.ctime(x)))\n",
    "mh_df['date'] = mh_df.created_utc.apply(lambda x: pd.to_datetime(time.ctime(x)))\n",
    "\n",
    "depression3['date'] = depression3.created_utc.apply(lambda x: pd.to_datetime(time.ctime(x)))\n",
    "depression['date'] = depression.created_utc.apply(lambda x: pd.to_datetime(time.ctime(x)))\n",
    "\n",
    "mh_df2.drop_duplicates(subset=['id'], inplace=True)\n",
    "mh_df.drop_duplicates(subset=['id'], inplace=True)\n",
    "\n",
    "depression3.drop_duplicates(subset=['id'], inplace=True)\n",
    "depression.drop_duplicates(subset=['id'], inplace=True)\n",
    "\n",
    "df_full = pd.concat([mh_df, mh_df2[mh_df2.date.dt.month!=10], depression, depression3[depression3.date.dt.month !=10]], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='date,date'>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# make sure theres a relatively even distribution for all months in concatenated data\n",
    "\n",
    "df_full.groupby([df_full[\"date\"].dt.year, df_full[\"date\"].dt.month]).size().plot(kind=\"bar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>id</th>\n",
       "      <th>author</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>title</th>\n",
       "      <th>selftext</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-10-11 16:39:05</td>\n",
       "      <td>dglq7k</td>\n",
       "      <td>liznormal23</td>\n",
       "      <td>mentalhealth</td>\n",
       "      <td>Mental Health Gray Area. Please help.</td>\n",
       "      <td>*TRIGGER WARNING: EATING DISORDER AND SUBSTANC...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-10-11 16:34:59</td>\n",
       "      <td>dgloc1</td>\n",
       "      <td>tacobean87</td>\n",
       "      <td>mentalhealth</td>\n",
       "      <td>what’s wrong with me ?</td>\n",
       "      <td>every single time i read something my mind blu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-10-11 16:22:09</td>\n",
       "      <td>dglieu</td>\n",
       "      <td>AquilaVI</td>\n",
       "      <td>mentalhealth</td>\n",
       "      <td>I'm trying to deal with a deadly car crash. (A...</td>\n",
       "      <td>Hello, people! A little backstory. I'll try to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-10-11 16:18:16</td>\n",
       "      <td>dglgl6</td>\n",
       "      <td>Mrcoolbaby</td>\n",
       "      <td>mentalhealth</td>\n",
       "      <td>Overwhelmed</td>\n",
       "      <td>I feel like my life is on loop. All the same k...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-10-11 16:15:26</td>\n",
       "      <td>dglfcf</td>\n",
       "      <td>TheA55M4N</td>\n",
       "      <td>mentalhealth</td>\n",
       "      <td>Anxiety and obsessions</td>\n",
       "      <td>I wrote my story here</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51984</th>\n",
       "      <td>2019-09-19 11:34:17</td>\n",
       "      <td>d6gke6</td>\n",
       "      <td>keenstir</td>\n",
       "      <td>depression</td>\n",
       "      <td>Calling in Sick</td>\n",
       "      <td>I have called in sick at least 10 times since ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51985</th>\n",
       "      <td>2019-09-19 11:33:20</td>\n",
       "      <td>d6gjwp</td>\n",
       "      <td>Jellybeanxx</td>\n",
       "      <td>depression</td>\n",
       "      <td>conversation with dad</td>\n",
       "      <td>please read. i have been on the journey for lo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51986</th>\n",
       "      <td>2019-09-19 11:31:06</td>\n",
       "      <td>d6gisp</td>\n",
       "      <td>DankDank24</td>\n",
       "      <td>depression</td>\n",
       "      <td>My gf left me because she turned out to be les...</td>\n",
       "      <td>I just miss her a lot, she's already moved on ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51987</th>\n",
       "      <td>2019-09-19 11:29:09</td>\n",
       "      <td>d6ghvp</td>\n",
       "      <td>feriou02</td>\n",
       "      <td>depression</td>\n",
       "      <td>Am I getting worse?</td>\n",
       "      <td>hello everyone. A long body of text for contex...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51988</th>\n",
       "      <td>2019-09-19 11:27:47</td>\n",
       "      <td>d6gh7s</td>\n",
       "      <td>Meulinia</td>\n",
       "      <td>depression</td>\n",
       "      <td>Has anyone thought about not using any medicat...</td>\n",
       "      <td>Hi, My mom keeps pushing me to stop with my me...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>48281 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     date      id       author     subreddit  \\\n",
       "0     2019-10-11 16:39:05  dglq7k  liznormal23  mentalhealth   \n",
       "1     2019-10-11 16:34:59  dgloc1   tacobean87  mentalhealth   \n",
       "2     2019-10-11 16:22:09  dglieu     AquilaVI  mentalhealth   \n",
       "3     2019-10-11 16:18:16  dglgl6   Mrcoolbaby  mentalhealth   \n",
       "4     2019-10-11 16:15:26  dglfcf    TheA55M4N  mentalhealth   \n",
       "...                   ...     ...          ...           ...   \n",
       "51984 2019-09-19 11:34:17  d6gke6     keenstir    depression   \n",
       "51985 2019-09-19 11:33:20  d6gjwp  Jellybeanxx    depression   \n",
       "51986 2019-09-19 11:31:06  d6gisp   DankDank24    depression   \n",
       "51987 2019-09-19 11:29:09  d6ghvp     feriou02    depression   \n",
       "51988 2019-09-19 11:27:47  d6gh7s     Meulinia    depression   \n",
       "\n",
       "                                                   title  \\\n",
       "0                  Mental Health Gray Area. Please help.   \n",
       "1                                 what’s wrong with me ?   \n",
       "2      I'm trying to deal with a deadly car crash. (A...   \n",
       "3                                            Overwhelmed   \n",
       "4                                 Anxiety and obsessions   \n",
       "...                                                  ...   \n",
       "51984                                    Calling in Sick   \n",
       "51985                              conversation with dad   \n",
       "51986  My gf left me because she turned out to be les...   \n",
       "51987                                Am I getting worse?   \n",
       "51988  Has anyone thought about not using any medicat...   \n",
       "\n",
       "                                                selftext  \n",
       "0      *TRIGGER WARNING: EATING DISORDER AND SUBSTANC...  \n",
       "1      every single time i read something my mind blu...  \n",
       "2      Hello, people! A little backstory. I'll try to...  \n",
       "3      I feel like my life is on loop. All the same k...  \n",
       "4                                 I wrote my story here   \n",
       "...                                                  ...  \n",
       "51984  I have called in sick at least 10 times since ...  \n",
       "51985  please read. i have been on the journey for lo...  \n",
       "51986  I just miss her a lot, she's already moved on ...  \n",
       "51987  hello everyone. A long body of text for contex...  \n",
       "51988  Hi, My mom keeps pushing me to stop with my me...  \n",
       "\n",
       "[48281 rows x 6 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove indents and urls and double spaces\n",
    "df_full['selftext'] = df_full.selftext.map(lambda x: re.sub('\\n',' ',str(x)))\n",
    "df_full['selftext'] = df_full.selftext.map(lambda x: re.sub('  ',' ',str(x)))\n",
    "df_full['selftext'] = df_full.selftext.map(lambda x: replace_urls(x))\n",
    "\n",
    "# remove deleted or removed posts \n",
    "cols_of_interest = ['date', 'id', 'author', 'subreddit', 'title', 'selftext']\n",
    "df_full_clean = df_full[(df_full.selftext != '[removed]') & (df_full.selftext != '[deleted]')].copy()\n",
    "df_full_clean[cols_of_interest]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = ['feel',\n",
    " 'want',\n",
    " 'myself',\n",
    " 'people',\n",
    " 'help',\n",
    " 'depression',\n",
    " 'nan',\n",
    " 'fucking',\n",
    " 'mental',\n",
    " 'hate',\n",
    " 'health',\n",
    " 'life',\n",
    " 'need',\n",
    " 'anxiety',\n",
    " 'talk',\n",
    " 'anymore',\n",
    " 'die',\n",
    " 'depressed',\n",
    " 'friends',\n",
    " 'fuck',\n",
    " 'feeling',\n",
    "#  'kill',\n",
    " 'time',\n",
    " 'shit',\n",
    " 'tired',\n",
    " 'happy',\n",
    " 'better',\n",
    " 'things',\n",
    " 'going',\n",
    " 'bad',\n",
    " 'way',\n",
    " 'care',\n",
    " 'good',\n",
    " 'wish',\n",
    " 'person',\n",
    " 'sad',\n",
    " 'day',\n",
    " 'makes',\n",
    " 'years',\n",
    " 'right',\n",
    " 'tell',\n",
    " 'self',\n",
    " 'love',\n",
    " 'worse',\n",
    " 'try',\n",
    " 'thoughts',\n",
    " 'live',\n",
    " 'friend',\n",
    " 'stop',\n",
    " 'feel',\n",
    " 'help',\n",
    " 'nan',\n",
    " 'people',\n",
    " 'fucking',\n",
    " 'hate',\n",
    " 'myself',\n",
    " 'mental',\n",
    " 'health',\n",
    " 'depressed',\n",
    " 'fuck',\n",
    " 'shit',\n",
    " 'self',\n",
    " 'person',\n",
    " 'makes',\n",
    " 'friends',\n",
    " 'feeling',\n",
    " 'better',\n",
    " 'depression',\n",
    " 'wanna',\n",
    " 'sad',\n",
    " 'good',\n",
    " 'way',\n",
    " 'try',\n",
    " 'understand',\n",
    " 'wrong',\n",
    " 'lonely',\n",
    " 'advice',\n",
    "'&amp;#x200B;',\n",
    "  'lose',\n",
    " 'find',\n",
    " 'care',\n",
    " 'feelings',\n",
    " 'idk',\n",
    " 'emotions',\n",
    " 'bad',\n",
    " 'issues',\n",
    " 'talking',\n",
    " 'stupid',\n",
    " 'actually',\n",
    " 'ask',\n",
    " 'like',\n",
    " 'right',\n",
    " 'thoughts',\n",
    " 'guilty',\n",
    " 'illness',\n",
    " 'life',\n",
    " 'therapy',\n",
    " 'things',\n",
    " 'social','best', 'bit', 'lot', 'great', 'says', 'getting', 'numb', 'come', 'amp', 'thing', 'little', 'today', 'started', 'maybe', 'feels', 'feel', 'feeling',\n",
    "\"told\", 'tomorrow', 'everyday', 'future', 'reason', 'pay', 'got', 'said', 'everyday', 'tomorrow', 'week', 'old', 'start', 'anxious', 'able', 'tried', 'features']+ ['think', 'thinking', 'happen', 'look', 'not', 'have', 'will', 'ill', 'sorry', 'alot', 'point', 'cuz', 'kinda', 'tell', 'exist', 'wait','post', 'have'] + ['let','happen','think','word','kinda','say','matt']\n",
    "              \n",
    "              \n",
    "              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path = '/Users/collinswestnedge/programming/Metis_Online/project_04/pickles/'\n",
    "\n",
    "# with open(path+'stop_words_test.pickle', 'wb') as file:\n",
    "#     pickle.dump(set(stop_words), file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(path+'stop_words_test.pickle', 'rb') as file:\n",
    "#     stop_words = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pipeline for topic modeling... for speed going to pass all documents\n",
    "# to be cleaned with spacy and treat it as a preprocessing step (following their documentation)\n",
    "\n",
    "class NLPPipe:\n",
    "    \n",
    "    def __init__(self, vectorizer, tokenizer, disable, pos, lemma=False):\n",
    "        \n",
    "        self.vectorizer = vectorizer\n",
    "        self.tokenize = tokenizer\n",
    "        self.disable = disable\n",
    "        self.pos_list = pos\n",
    "        self.lemma = lemma\n",
    "    \n",
    "    def process_text(self, text):\n",
    "\n",
    "        nlp = spacy.load(\"en_core_web_sm\")\n",
    "        nlp.vocab[\" \"].is_stop = True\n",
    "        nlp.vocab[\"like\"].is_stop = True\n",
    "        nlp.vocab[\"think\"].is_stop = True\n",
    "        nlp.vocab[\"know\"].is_stop = True\n",
    "        nlp.Defaults.stop_words |= set(stop_words)\n",
    "\n",
    "        text_full = [] \n",
    "        for doc in nlp.pipe(text, disable=self.disable):\n",
    "            # if part of speech list isnt empty return matches for pos\n",
    "            if self.pos_list:\n",
    "                tokens = [(ent.text) for ent in doc if not ent.is_stop and not ent.is_punct and ent.pos_ in self.pos_list]\n",
    "                cleaned_text = \" \".join(tokens)\n",
    "                text_full.append(cleaned_text)\n",
    "            elif self.lemma == True:\n",
    "                tokens = [(ent.lemma_) for ent in doc if not ent.is_stop and not ent.is_punct]\n",
    "                cleaned_text = \" \".join(tokens)\n",
    "                text_full.append(cleaned_text)\n",
    "            else:\n",
    "                tokens = [(ent.text) for ent in doc if not ent.is_stop and not ent.is_punct]\n",
    "                cleaned_text = \" \".join(tokens)\n",
    "                text_full.append(cleaned_text)\n",
    "\n",
    "        return text_full\n",
    "    \n",
    "    def fit(self, text):\n",
    "        clean_text = self.process_text(text)\n",
    "        return self.vectorizer.fit(clean_text)\n",
    "    \n",
    "    def transform(self, text):\n",
    "        clean_text = self.process_text(text)\n",
    "        return self.vectorizer.transform(clean_text)\n",
    "    \n",
    "    def fit_transform(self, text):\n",
    "        clean_text = self.process_text(text)\n",
    "        return self.vectorizer.fit_transform(clean_text)\n",
    "    \n",
    "    def display_topics(self, model, feature_names, no_top_words, topic_names=None):\n",
    "        for ix, topic in enumerate(model.components_):\n",
    "            if not topic_names or not topic_names[ix]:\n",
    "                print(\"\\nTopic \", ix)\n",
    "            else:\n",
    "                print(\"\\nTopic: '\",topic_names[ix],\"'\")\n",
    "            print(\", \".join([feature_names[i]\n",
    "                            for i in topic.argsort()[:-no_top_words - 1:-1]])) \n",
    "    \n",
    "    def fit_transform_nmf(self, nmf, word_vec, feature_names, n_words):\n",
    "        '''\n",
    "        Description:\n",
    "        fit and display top words from nmf\n",
    "        on vectorized words\n",
    "        '''\n",
    "        doc_topic = nmf.fit_transform(word_vect)\n",
    "        self.display_topics(nmf, feature_names, n_words)\n",
    "        return doc_topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# corpus = df_full_clean[['title','selftext']].sample(1)\n",
    "# corpus.title.values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# this is for debugging the text preprocessing step comment out later...\n",
    "\n",
    "# def process_text(text, pos_list, lemma=False):\n",
    "\n",
    "#     nlp = spacy.load(\"en_core_web_sm\")\n",
    "# #     nlp.vocab[\"myself\"].is_stop = False\n",
    "#     nlp.vocab[\" \"].is_stop = True\n",
    "# #     nlp.vocab[\"like\"].is_stop = True\n",
    "# #     nlp.vocab[\"think\"].is_stop = True\n",
    "# #     nlp.vocab[\"know\"].is_stop = True\n",
    "#     nlp.Defaults.stop_words |= stop_words\n",
    "\n",
    "\n",
    "#     text_full = [] \n",
    "#     for doc in nlp.pipe(text, disable=['parser', 'ner']):\n",
    "#         # if part of speech list isnt empty return matches for pos\n",
    "#         if pos_list:\n",
    "#             tokens = [(ent.pos_) for ent in doc if not ent.is_stop and not ent.is_punct and ent.pos_ in pos_list]\n",
    "#             cleaned_text = \" \".join(tokens)\n",
    "#             text_full.append(cleaned_text)\n",
    "#         elif lemma == True:\n",
    "#             tokens = [(ent.lemma_) for ent in doc if not ent.is_stop and not ent.is_punct]\n",
    "#             cleaned_text = \" \".join(tokens)\n",
    "#             text_full.append(cleaned_text)\n",
    "#         else:\n",
    "#             tokens = [(ent.text) for ent in doc if not ent.is_stop and not ent.is_punct]\n",
    "#             cleaned_text = \" \".join(tokens)\n",
    "#             text_full.append(cleaned_text)\n",
    "            \n",
    "#     return text_full\n",
    "\n",
    "# # print(corpus.title.values[0])\n",
    "# # print()\n",
    "\n",
    "# a = process_text(['abandon', 'abandoned', 'abandonment', 'running', 'ran', 'runs'], pos_list=[], lemma=False)\n",
    "# a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding title of post and post as one column to get a little more information for topic modeling\n",
    "\n",
    "df_full_clean['text_title'] = df_full_clean.title + ' ' + df_full_clean.selftext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_full_clean.to_csv('/Users/collinswestnedge/programming/Metis_Online/project_04/data/data_full_clean.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>all_awardings</th>\n",
       "      <th>allow_live_comments</th>\n",
       "      <th>author</th>\n",
       "      <th>author_flair_css_class</th>\n",
       "      <th>author_flair_richtext</th>\n",
       "      <th>author_flair_text</th>\n",
       "      <th>author_flair_type</th>\n",
       "      <th>author_fullname</th>\n",
       "      <th>author_patreon_flair</th>\n",
       "      <th>awarders</th>\n",
       "      <th>...</th>\n",
       "      <th>banned_by</th>\n",
       "      <th>date</th>\n",
       "      <th>author_created_utc</th>\n",
       "      <th>category</th>\n",
       "      <th>content_categories</th>\n",
       "      <th>media_embed</th>\n",
       "      <th>removal_reason</th>\n",
       "      <th>secure_media_embed</th>\n",
       "      <th>suggested_sort</th>\n",
       "      <th>text_title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>liznormal23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>text</td>\n",
       "      <td>t2_3e4lklg</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-10-11 16:39:05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Mental Health Gray Area. Please help. *TRIGGER...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>tacobean87</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>text</td>\n",
       "      <td>t2_4kyj8fmi</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-10-11 16:34:59</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>what’s wrong with me ? every single time i rea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>AquilaVI</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>text</td>\n",
       "      <td>t2_j2m5u</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-10-11 16:22:09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>I'm trying to deal with a deadly car crash. (A...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>Mrcoolbaby</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>text</td>\n",
       "      <td>t2_3i29eu4o</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-10-11 16:18:16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Overwhelmed I feel like my life is on loop. Al...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>TheA55M4N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>text</td>\n",
       "      <td>t2_4cu0omsq</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-10-11 16:15:26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Anxiety and obsessions I wrote my story here</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51984</th>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>keenstir</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>text</td>\n",
       "      <td>t2_5nkip</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-09-19 11:34:17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>confidence</td>\n",
       "      <td>Calling in Sick I have called in sick at least...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51985</th>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>Jellybeanxx</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>text</td>\n",
       "      <td>t2_5fux80z</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-09-19 11:33:20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>confidence</td>\n",
       "      <td>conversation with dad please read. i have been...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51986</th>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>DankDank24</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>text</td>\n",
       "      <td>t2_2vgrg0on</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-09-19 11:31:06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>confidence</td>\n",
       "      <td>My gf left me because she turned out to be les...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51987</th>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>feriou02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>text</td>\n",
       "      <td>t2_21bgdfsf</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-09-19 11:29:09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>confidence</td>\n",
       "      <td>Am I getting worse? hello everyone. A long bod...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51988</th>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>Meulinia</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>text</td>\n",
       "      <td>t2_pootbks</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-09-19 11:27:47</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>confidence</td>\n",
       "      <td>Has anyone thought about not using any medicat...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>48281 rows × 90 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      all_awardings allow_live_comments       author  author_flair_css_class  \\\n",
       "0                []               False  liznormal23                     NaN   \n",
       "1                []               False   tacobean87                     NaN   \n",
       "2                []               False     AquilaVI                     NaN   \n",
       "3                []               False   Mrcoolbaby                     NaN   \n",
       "4                []               False    TheA55M4N                     NaN   \n",
       "...             ...                 ...          ...                     ...   \n",
       "51984            []               False     keenstir                     NaN   \n",
       "51985            []               False  Jellybeanxx                     NaN   \n",
       "51986            []               False   DankDank24                     NaN   \n",
       "51987            []               False     feriou02                     NaN   \n",
       "51988            []               False     Meulinia                     NaN   \n",
       "\n",
       "      author_flair_richtext author_flair_text author_flair_type  \\\n",
       "0                        []               NaN              text   \n",
       "1                        []               NaN              text   \n",
       "2                        []               NaN              text   \n",
       "3                        []               NaN              text   \n",
       "4                        []               NaN              text   \n",
       "...                     ...               ...               ...   \n",
       "51984                    []               NaN              text   \n",
       "51985                    []               NaN              text   \n",
       "51986                    []               NaN              text   \n",
       "51987                    []               NaN              text   \n",
       "51988                    []               NaN              text   \n",
       "\n",
       "      author_fullname author_patreon_flair awarders  ...  banned_by  \\\n",
       "0          t2_3e4lklg                False       []  ...        NaN   \n",
       "1         t2_4kyj8fmi                False       []  ...        NaN   \n",
       "2            t2_j2m5u                False       []  ...        NaN   \n",
       "3         t2_3i29eu4o                False       []  ...        NaN   \n",
       "4         t2_4cu0omsq                False       []  ...        NaN   \n",
       "...               ...                  ...      ...  ...        ...   \n",
       "51984        t2_5nkip                False      NaN  ...        NaN   \n",
       "51985      t2_5fux80z                False      NaN  ...        NaN   \n",
       "51986     t2_2vgrg0on                False      NaN  ...        NaN   \n",
       "51987     t2_21bgdfsf                False      NaN  ...        NaN   \n",
       "51988      t2_pootbks                False      NaN  ...        NaN   \n",
       "\n",
       "                     date  author_created_utc category content_categories  \\\n",
       "0     2019-10-11 16:39:05                 NaN      NaN                NaN   \n",
       "1     2019-10-11 16:34:59                 NaN      NaN                NaN   \n",
       "2     2019-10-11 16:22:09                 NaN      NaN                NaN   \n",
       "3     2019-10-11 16:18:16                 NaN      NaN                NaN   \n",
       "4     2019-10-11 16:15:26                 NaN      NaN                NaN   \n",
       "...                   ...                 ...      ...                ...   \n",
       "51984 2019-09-19 11:34:17                 NaN      NaN                NaN   \n",
       "51985 2019-09-19 11:33:20                 NaN      NaN                NaN   \n",
       "51986 2019-09-19 11:31:06                 NaN      NaN                NaN   \n",
       "51987 2019-09-19 11:29:09                 NaN      NaN                NaN   \n",
       "51988 2019-09-19 11:27:47                 NaN      NaN                NaN   \n",
       "\n",
       "      media_embed removal_reason  secure_media_embed  suggested_sort  \\\n",
       "0             NaN            NaN                 NaN             NaN   \n",
       "1             NaN            NaN                 NaN             NaN   \n",
       "2             NaN            NaN                 NaN             NaN   \n",
       "3             NaN            NaN                 NaN             NaN   \n",
       "4             NaN            NaN                 NaN             NaN   \n",
       "...           ...            ...                 ...             ...   \n",
       "51984         NaN            NaN                 NaN      confidence   \n",
       "51985         NaN            NaN                 NaN      confidence   \n",
       "51986         NaN            NaN                 NaN      confidence   \n",
       "51987         NaN            NaN                 NaN      confidence   \n",
       "51988         NaN            NaN                 NaN      confidence   \n",
       "\n",
       "                                              text_title  \n",
       "0      Mental Health Gray Area. Please help. *TRIGGER...  \n",
       "1      what’s wrong with me ? every single time i rea...  \n",
       "2      I'm trying to deal with a deadly car crash. (A...  \n",
       "3      Overwhelmed I feel like my life is on loop. Al...  \n",
       "4          Anxiety and obsessions I wrote my story here   \n",
       "...                                                  ...  \n",
       "51984  Calling in Sick I have called in sick at least...  \n",
       "51985  conversation with dad please read. i have been...  \n",
       "51986  My gf left me because she turned out to be les...  \n",
       "51987  Am I getting worse? hello everyone. A long bod...  \n",
       "51988  Has anyone thought about not using any medicat...  \n",
       "\n",
       "[48281 rows x 90 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_full_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# corpus = df_full_clean.selftext\n",
    "corpus = df_full_clean.text_title\n",
    "\n",
    "tfdif_vect = TfidfVectorizer(\n",
    "                             strip_accents='unicode',\n",
    "                             min_df = 5,\n",
    "                             ngram_range=(1, 1),\n",
    "                             max_df = .5, \n",
    "                             token_pattern = r'\\b[a-zA-Z]{3,}\\b'\n",
    "                             )\n",
    "\n",
    "pipeline = NLPPipe(vectorizer=tfdif_vect,\n",
    "                  tokenizer=None,\n",
    "                  disable=[\"tagger\",\"parser\", \"ner\"],\n",
    "                  pos=[],\n",
    "                  lemma=True,\n",
    "                  )\n",
    "\n",
    "word_vect = pipeline.fit_transform(corpus).toarray()\n",
    "features = pipeline.vectorizer.get_feature_names()\n",
    "\n",
    "nmf = NMF(16, alpha=.04, l1_ratio=.5, random_state=0, max_iter=700, init='nndsvd')\n",
    "doc_topic = pipeline.fit_transform_nmf(nmf, word_vect, features, n_words=100)\n",
    "term_topic = nmf.components_\n",
    "\n",
    "# reg_nmf = NMF(11, alpha=.05, l1_ratio=.5, random_state=0, max_iter=700)\n",
    "# reg_doc_topic = pipeline.fit_transform_nmf(nmf, word_vect, features, n_words=100)\n",
    "# reg_topic_term = nmf.components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.DataFrame(word_vect)\n",
    "# df.columns = pipeline.vectorizer.get_feature_names()\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/Users/collinswestnedge/programming/Metis_Online/project_04/pickles/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(path+'anxiety.pickle', 'wb') as file:\n",
    "#     pickle.dump(nmf, file, protocol=4)\n",
    "#     pickle.dump(doc_topic, file, protocol=4)\n",
    "#     pickle.dump(word_vect, file, protocol=4)\n",
    "#     pickle.dump(pipeline.vectorizer, file, protocol=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_topics(model, feature_names, no_top_words, topic_names=None):\n",
    "    for ix, topic in enumerate(model.components_):\n",
    "        if not topic_names or not topic_names[ix]:\n",
    "            print(\"\\nTopic \", ix)\n",
    "        else:\n",
    "            print(\"\\nTopic: '\",topic_names[ix],\"'\")\n",
    "        print(\", \".join([feature_names[i]\n",
    "                        for i in topic.argsort()[:-no_top_words - 1:-1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# once you feel good about topics you should move code below to new notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(path+'no_lemma_topic_model_big.pickle', 'rb') as file:\n",
    "    reg_nmf = pickle.load(file)\n",
    "    reg_doc_topic = pickle.load(file)\n",
    "    reg_word_vec = pickle.load(file)\n",
    "    reg_vectorizer = pickle.load(file)\n",
    "    \n",
    "    \n",
    "with open(path+'lemma_topic_model_big.pickle', 'rb') as file:\n",
    "    nmf_lemma = pickle.load(file)\n",
    "    doc_topic_lemma = pickle.load(file)\n",
    "    word_vec_lemma = pickle.load(file)\n",
    "    vectorizer_lemma = pickle.load(file)\n",
    "    \n",
    "\n",
    "with open(path+'no_lemma_topic_model_big2.pickle', 'rb') as file:\n",
    "    reg_nmf_large = pickle.load(file)\n",
    "    reg_doc_topic_large = pickle.load(file)\n",
    "    reg_word_vec_large = pickle.load(file)\n",
    "    reg_vectorizer_large = pickle.load(file)\n",
    "    \n",
    "\n",
    "with open(path+'anxiety.pickle', 'rb') as file:\n",
    "    anxiety_nmf = pickle.load(file)\n",
    "    anxiety_doc_topic = pickle.load(file)\n",
    "    anxiety_word_vec = pickle.load(file)\n",
    "    anxiety_reg_vectorizer = pickle.load(file)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Topic  0\n",
      "therapist, medication, doctor, meds, disorder, advice, diagnosed, psychiatrist, taking, panic, bipolar, suicidal, appointment, symptoms, having, scared, diagnosis, sure, seeing, antidepressants, attacks, recently, experience, adhd, severe, effects, months, new, mood, treatment, attack, prescribed, insurance, ocd, hospital, past, weeks, struggling, different, thanks, ptsd, doctors, medications, therapists, psychologist, wondering, eating, anti, appreciated, finally, depressive, currently, problems, ago, etc, looking, parents, starting, personality, normal, bpd, professional, worried, major, harm, thank, long, helped, problem, dealing, question, kind, experiences, dose, session, month, zoloft, idea, issue, pretty, working, episode, medicine, episodes, taken, tips, psych, medical, deal, prozac, borderline, pills, sessions, support, questions, lexapro, disorders, trying, stopped, similar\n",
      "\n",
      "Topic  1\n",
      "need, advice, listen, scared, vent, support, hug, chat, struggling, needs, okay, hospital, message, parents, somebody, telling, hello, open, professional, insurance, guys, reach, break, place, situation, problem, chest, handle, hey, fix, posting, desperately, stuff, encouragement, trust, hard, money, desperate, willing, boyfriend, afford, lost, attention, free, harm, afraid, change, suicidal, hurting, important, girlfriend, thank, order, needed, sure, online, psychologist, kind, available, nervous, stressed, lately, needing, text, phone, breakdown, thanks, counselor, use, cut, tips, knows, speak, relationship, sick, helping, spiraling, bring, pls, seek, reaching, problems, check, sub, reddit, currently, therapists, deal, write, appreciated, worry, guidance, appreciate, seriously, space, words, lied, convince, tonight, explain\n",
      "\n",
      "Topic  2\n",
      "school, high, college, year, parents, class, classes, grades, semester, grade, home, middle, online, motivation, teachers, study, summer, student, homework, bullied, teacher, senior, university, graduate, failing, group, went, studying, games, kid, graduated, dropped, pretty, failed, junior, freshman, finish, fun, elementary, counselor, gon, advice, math, students, stressed, probably, failure, test, stuff, stress, drop, degree, fail, schools, barely, gpa, play, missed, sit, basically, smart, assignments, exams, education, age, currently, highschool, sophomore, bullying, video, playing, focus, girls, literally, career, learn, graduating, lazy, hang, exam, program, pass, tests, gotten, making, second, hard, kids, major, finished, learning, honestly, new, sucks, hated, quarantine, classmates, dropping, late, graduation\n",
      "\n",
      "Topic  3\n",
      "work, job, working, home, money, new, jobs, quit, hours, hard, college, boss, days, trying, living, worked, motivation, stress, lost, house, stuck, car, months, afford, place, leave, sick, fired, bills, career, making, company, family, weeks, wife, degree, energy, rent, spend, struggling, manager, month, bed, barely, interview, stay, shift, drive, having, coworkers, lazy, office, failure, debt, food, morning, end, supposed, enjoy, miserable, focus, paying, paid, year, left, useless, covid, hour, stressed, position, husband, starting, finding, hobbies, stressful, moved, etc, apartment, weekend, gym, taking, field, business, currently, support, insurance, early, worth, student, country, rest, minimum, looking, quitting, unemployed, spent, current, graduated, city, works\n",
      "\n",
      "Topic  4\n",
      "hard, end, trying, world, mind, head, pain, real, family, normal, hope, matter, away, sure, amp, having, living, problems, constantly, long, hurt, times, brain, kind, thought, probably, change, mean, guess, believe, body, okay, making, sense, honestly, inside, stuff, deal, problem, fear, cause, different, deserve, read, weird, hurts, remember, death, pretty, enjoy, place, worth, happiness, looking, gets, moment, afraid, completely, literally, truly, hear, alive, happens, sick, control, words, fact, close, etc, reality, attention, comes, reading, negative, god, human, gon, dead, gone, music, idea, true, cares, face, stay, saying, angry, usually, hell, use, constant, goes, stuck, explain, far, nice, suffering, sadness, lately, writing\n",
      "\n",
      "Topic  5\n",
      "sleep, night, wake, bed, hours, sleeping, asleep, morning, eat, days, awake, fall, energy, waking, exhausted, woke, dreams, stay, lay, dream, nightmares, room, slept, nights, motivation, schedule, eating, scared, having, late, eyes, insomnia, usually, body, tonight, panic, crying, laying, barely, pills, hour, falling, home, mind, forever, drink, shower, cycle, food, taking, staying, literally, nightmare, work, happening, phone, past, escape, minutes, till, head, lately, attacks, nap, stomach, rest, worst, early, constantly, attack, normal, watching, drinking, pass, house, productive, brain, weeks, spend, sick, dying, watch, dark, deprivation, alive, sleepy, afternoon, physically, sit, gets, hoping, melatonin, weekends, constant, fine, later, times, goes, trouble, tips\n",
      "\n",
      "Topic  6\n",
      "mom, dad, parents, family, brother, sister, mother, house, home, father, room, money, child, mad, away, abusive, kids, scared, siblings, leave, died, angry, older, saying, called, kid, asked, telling, abuse, car, phone, mum, moved, left, thinks, living, came, younger, grandma, hospital, childhood, problems, wants, yelling, took, son, wanted, abused, age, stuff, daughter, went, step, young, parent, crying, anger, divorced, gets, found, fight, close, cancer, sisters, yelled, remember, brothers, children, upset, happened, husband, hurt, fault, blame, passed, emotionally, baby, tells, door, stay, support, boyfriend, situation, deal, hit, police, divorce, born, dog, believe, mentally, grade, argument, uncle, married, big, screaming, cause, saw, basically\n",
      "\n",
      "Topic  7\n",
      "kill, suicide, suicidal, killing, scared, end, gon, alive, death, pain, commit, hurt, dead, living, attempt, plan, thought, wanting, tonight, family, hospital, dying, attempted, soon, wanted, probably, gun, killed, suffering, cut, hell, coward, cares, seriously, god, pussy, harm, option, matter, painless, pills, courage, afraid, hotline, worthless, died, miserable, planning, planned, ready, cutting, worth, ideation, ugly, note, hope, wants, considering, deserve, telling, fucked, finally, forever, trying, pathetic, failed, goodbye, knife, peace, committing, cause, somebody, title, existing, gives, hopeless, honestly, urge, supposed, selfish, born, suffer, attempts, useless, waiting, failure, saying, reasons, drunk, hurting, guess, overdose, ward, horrible, drugs, knowing, parents, debt, bitch, damn\n",
      "\n",
      "Topic  8\n",
      "felt, year, ago, months, days, went, relationship, thought, past, wanted, lost, girl, long, weeks, happened, girlfriend, finally, boyfriend, left, broke, couple, new, month, night, guy, came, away, found, took, knew, asked, ended, home, later, met, stopped, remember, loved, times, talked, dating, yesterday, close, crying, decided, moved, break, pretty, sex, saw, kept, miss, needed, house, birthday, having, gone, cut, recently, half, completely, room, called, place, story, group, gave, worst, spent, cried, leave, hours, fine, hit, woke, suicide, saying, phone, text, changed, heart, coming, date, fell, eventually, guess, died, suicidal, car, drinking, turned, drunk, realized, minutes, forward, okay, passed, seeing, girls, liked\n",
      "\n",
      "Topic  9\n",
      "cry, crying, tears, cried, sadness, pain, eyes, okay, hurt, emotion, scream, laugh, angry, night, inside, normal, hug, lately, emotional, smile, breakdown, chest, hurts, scared, release, wanting, break, sit, bed, unable, times, upset, literally, anger, laughing, sensitive, control, randomly, happens, stressed, miss, everytime, gon, tear, songs, sick, sucks, panic, matter, bathroom, died, fine, express, cut, badly, verge, movie, mad, hide, watching, urge, listen, till, deal, overwhelmed, easily, cares, boyfriend, shaking, face, weird, heart, broken, dog, human, usually, floor, throat, faking, physical, attacks, held, strong, breaking, days, fake, burst, worthless, hold, calm, hour, storm, attack, ball, killing, curl, awful, room, listening, emotionally\n"
     ]
    }
   ],
   "source": [
    "display_topics(reg_nmf, reg_vectorizer.get_feature_names(), 100)\n",
    "# display_topics(nmf_lemma, vectorizer_lemma.get_feature_names(), 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Topic  0\n",
      "happen, mind, problem, think, hard, head, normal, sure, world, try, have, read, real, remember, mean, kind, amp, long, hear, feel, write, experience, look, change, moment, deal, time, brain, believe, cause, weird, stuff, hope, okay, pretty, worry, come, guess, constantly, sense, play, idea, watch, situation, different, matt, probably, struggle, enjoy, know, sound, place, realize, memory, fear, make, control, game, voice, question, listen, share, explain, completely, wonder, etc, video, usually, act, family, live, recently, thank, forget, face, body, get, past, learn, negative, big, conversation, want, see, say, music, away, lately, word, sort, help, fact, give, dream, interest, relate, reality, post, suffer, notice\n",
      "\n",
      "Topic  1\n",
      "not, have, will, scare, mind, stuff, parent, suicidal, cause, problem, worthless, everytime, cut, tho, fuck, bore, deserve, head, hard, alive, cant, annoy, handle, motivation, bother, confuse, dumb, fix, god, okay, game, matt, real, attack, pathetic, like, tell, girl, shitty, ask, know, atleast, rant, workout, lately, afraid, get, money, play, english, mad, highschool, shut, girlfriend, useless, panic, hate, probably, worth, trust, ppl, stick, terrible, brain, forget, force, vent, yes, exist, explain, type, literally, act, breakdown, hobby, laugh, fun, stand, tbh, post, family, inside, loser, change, use, fake, start, distract, sit, aswell, fast, honestly, give, hug, sense, basically, hold, enjoy, anybody, everyones\n",
      "\n",
      "Topic  2\n",
      "work, job, home, money, hard, hour, quit, new, stress, college, day, try, pay, boss, live, spend, month, place, apply, struggle, motivation, interview, bill, fire, career, company, stick, car, shift, family, house, drive, sick, degree, take, afford, manager, week, wife, make, energy, coworker, leave, weekend, waste, stay, failure, graduate, rend, focus, bed, move, enjoy, lose, finish, manage, suck, suppose, lazy, hire, clean, office, morning, long, position, motivate, debt, study, barely, goal, hobby, fail, exhaust, deal, give, worker, useless, interest, business, etc, miserable, field, change, buy, covid, customer, will, husband, currently, find, rest, train, stressful, have, sit, support, gym, plan, worth, get\n",
      "\n",
      "Topic  3\n",
      "therapist, medication, doctor, take, meds, psychiatrist, diagnose, disorder, panic, attack, appointment, advice, month, experience, suicidal, see, bipolar, antidepressant, have, diagnosis, symptom, help, scare, prescribe, ago, effect, hospital, week, struggle, session, treatment, harm, new, insurance, past, finally, severe, adhd, recently, mood, psychologist, episode, sure, question, long, different, deal, anti, pill, professional, dose, ocd, year, suicide, problem, ptsd, appreciate, drug, seek, cope, ask, parent, depressive, stop, worry, zoloft, suffer, medicine, currently, wonder, attempt, depressant, bpd, psych, thank, couple, visit, major, medical, start, test, prozac, lexapro, day, thanks, idea, cause, change, personality, etc, call, work, option, low, kind, patient, find, admit, prescription, nervous\n",
      "\n",
      "Topic  4\n",
      "sleep, wake, night, bed, hour, asleep, dream, morning, fall, day, awake, stay, nightmare, exhaust, energy, drink, pill, late, lie, take, room, panic, attack, eye, schedule, insomnia, have, tonight, nap, lay, home, shower, motivation, barely, week, happen, watch, mind, past, scare, usually, minute, early, cycle, forever, pass, rest, sit, till, phone, escape, weekend, body, wrong, alive, spend, head, light, literally, walk, hope, trouble, constantly, get, stress, dark, house, alarm, afternoon, long, time, brain, dread, fine, dead, couple, away, clean, half, yesterday, feel, headache, lately, repeat, reality, sleepy, constant, smoke, turn, normal, dye, remember, breathe, melatonin, run, stomach, productive, function, distract, usual\n",
      "\n",
      "Topic  5\n",
      "need, advice, vent, support, listen, hug, okay, chat, will, reach, scare, struggle, message, professional, hard, place, chest, tell, open, post, problem, help, hospital, somebody, fix, thank, appreciate, attention, insurance, important, situation, hello, hey, stress, seek, space, deal, money, parent, desperately, handle, sure, admit, stuff, free, check, encouragement, rant, worry, harm, desperate, trust, use, thanks, get, spiral, afford, bother, cut, order, text, afraid, psychologist, break, sub, kind, lately, online, system, sick, phone, guy, read, send, hotline, word, burden, overwhelm, offer, call, tip, breakdown, provide, answer, counselor, write, currently, comment, understand, hold, fine, suffer, figure, available, ready, reddit, realize, boyfriend, guidance, upset\n",
      "\n",
      "Topic  6\n",
      "school, high, class, year, college, grade, parent, fail, study, semester, teacher, graduate, student, bully, drop, home, motivation, online, miss, stress, middle, finish, summer, university, homework, exam, test, kid, senior, play, group, learn, game, skip, waste, freshman, math, pretty, junior, pass, failure, attend, assignment, counselor, smart, sit, fun, degree, barely, elementary, advice, struggle, gpa, take, course, stuff, probably, major, education, focus, suck, classmate, basically, hard, highschool, final, currently, career, begin, program, sophomore, hang, late, new, motivate, age, hate, pressure, interest, literally, lazy, academic, plan, start, bed, disappoint, art, think, talk, honestly, quarantine, will, apply, make, useless, girl, get, spend, read, video\n",
      "\n",
      "Topic  7\n",
      "kill, suicide, suicidal, scare, death, alive, end, dead, plan, live, want, commit, think, attempt, family, will, probably, matt, hell, world, dye, seriously, god, soon, gun, option, suffer, hope, tonight, worth, fail, cut, try, consider, coward, honestly, care, easy, die, hospital, harm, mean, worthless, pill, miserable, fuck, pussy, ugly, painless, know, pain, give, exist, afraid, title, courage, ready, guess, bear, overdose, knife, pathetic, literally, useless, keep, failure, hotline, convince, fact, crazy, inside, goodbye, urge, regret, forever, jump, drug, close, somebody, wake, survive, worry, weak, suppose, attention, peace, note, method, ideation, reason, horrible, hopeless, tell, write, damn, run, stab, accident, burden, continue\n",
      "\n",
      "Topic  8\n",
      "mom, dad, parent, family, brother, sister, mother, house, home, father, kid, room, child, leave, abuse, live, yell, call, young, away, ask, tell, money, sibling, mad, die, want, move, old, abusive, fight, angry, come, divorce, car, stay, say, scare, mum, phone, grow, know, scream, blame, hospital, take, age, grandma, childhood, keep, son, member, daughter, bring, see, believe, refuse, cousin, will, problem, beat, dog, stuff, think, close, hit, act, remember, step, anger, argument, talk, threaten, door, get, husband, visit, support, cancer, raise, marry, fault, cause, treat, turn, place, hear, find, clean, deal, baby, man, upset, uncle, walk, kick, aunt, give, drug, hate\n",
      "\n",
      "Topic  9\n",
      "cry, tear, sadness, okay, feel, laugh, night, break, eye, panic, breakdown, attack, scream, hour, bed, emotion, sit, happen, hug, emotional, day, smile, upset, literally, angry, die, crying, lately, normal, bathroom, shake, inside, hold, time, release, minute, watch, yesterday, calm, fine, scare, room, chest, movie, song, have, come, yell, stress, overwhelm, miss, control, listen, randomly, floor, want, remember, ask, burst, hit, dog, home, unable, sob, fake, ago, sensitive, anger, birthday, face, finally, moment, think, usually, verge, suddenly, boyfriend, small, see, trigger, suck, easily, comfort, embarrass, sick, care, hard, everytime, hear, hide, mad, baby, fun, bottle, throat, try, shower, car, uncontrollably, cat\n",
      "\n",
      "Topic  10\n",
      "end, relationship, break, leave, month, lose, year, want, girl, ago, feel, girlfriend, long, love, date, guy, meet, boyfriend, away, day, past, new, close, finally, know, miss, week, drink, come, move, hope, hang, couple, find, stay, care, fall, think, home, night, take, live, sex, see, spend, house, late, decide, plan, heart, give, birthday, ask, talk, time, cheat, keep, text, cut, have, like, push, place, stop, turn, completely, message, fight, hold, suicide, half, ruin, friendship, woman, single, soon, pass, wrong, honestly, pretty, group, apart, get, begin, family, lie, recently, eventually, contact, forward, change, trust, start, call, crush, partner, reach, guess, interest, toxic\n",
      "\n",
      "Topic  11\n",
      "hurt, pain, cut, deserve, away, hard, okay, heart, harm, suffer, body, care, love, sick, scare, chest, physically, will, end, head, physical, alive, cause, world, leave, push, angry, inside, try, break, family, badly, matt, stomach, fight, get, horrible, deal, urge, live, emotionally, ruin, god, suicide, arm, hit, strong, painful, burden, anger, death, know, trust, emotional, guilt, close, worth, worthless, selfish, fault, deep, constant, hope, dead, breathe, smile, miss, scream, honestly, forgive, run, wrist, one, long, keep, easy, continue, throw, awful, tonight, mad, damn, cope, stop, handle, ache, dye, sadness, upset, scar, fuck, mean, wrong, disappear, blood, act, blame, misery, piece, bleed\n",
      "\n",
      "Topic  12\n",
      "eat, food, weight, disorder, body, day, healthy, bed, gain, hungry, lose, meal, appetite, drink, exercise, fat, shower, binge, sick, starve, skinny, stomach, diet, pound, calory, motivation, dinner, force, energy, throw, habit, barely, disgust, eating, clean, lunch, breakfast, water, unhealthy, cook, overweight, anorexia, brush, struggle, tooth, junk, enjoy, fast, stress, usually, weigh, taste, underweight, smoke, recently, past, gym, low, home, physically, small, snack, workout, control, mirror, lately, pizza, literally, bite, hair, worry, wash, house, clothe, stop, slowly, thin, loss, normal, purge, skin, obese, make, constantly, week, tip, nauseous, spend, vomit, ugly, recover, chore, cause, buy, anorexic, sure, watch, walk, bring, sugar\n"
     ]
    }
   ],
   "source": [
    "display_topics(nmf_lemma, vectorizer_lemma.get_feature_names(), 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import scattertext as st\n",
    "\n",
    "# category = 'relationships'\n",
    "# a = topic_doc_df[topic_doc_df.max_label == category].sample(1000)\n",
    "# b = topic_doc_df[topic_doc_df.max_label != category].sample(1000)\n",
    "\n",
    "# sample = pd.concat([a,b])\n",
    "\n",
    "# nlp = spacy.load(\"en_core_web_sm\")\n",
    "# nlp.vocab[\" \"].is_stop = True\n",
    "# nlp.vocab[\"like\"].is_stop = True\n",
    "# nlp.vocab[\"think\"].is_stop = True\n",
    "# nlp.vocab[\"know\"].is_stop = True\n",
    "# nlp.Defaults.stop_words |= set(stop_words)\n",
    "\n",
    "# corpus = st.CorpusFromPandas(sample,\n",
    "#                              category_col='max_label',\n",
    "#                              text_col='text_title',\n",
    "#                              nlp=nlp\n",
    "#                             ).build().remove_terms(set(stop_words), ignore_absences=True)\n",
    "\n",
    "# html = st.produce_scattertext_explorer(corpus,\n",
    "#           category=category,\n",
    "#           category_name=category,\n",
    "#           not_category_name='not '+ category,\n",
    "#           width_in_pixels=1000,\n",
    "#           minimum_term_frequency=10,\n",
    "#           pmi_threshold_coefficient=3,\n",
    "#           metadata=None)\n",
    "\n",
    "# open('scattertext_demo.html', 'wb').write(html.encode('utf-8'));"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
